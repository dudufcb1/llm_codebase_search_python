"""FastMCP server for codebase search (LOCAL MODE - code-index-cli compatible).

This server is specifically designed to work with code-index-cli indexed workspaces.
It requires explicit qdrantCollection parameter from .codebase/state.json.

Use this when:
- Your workspace is indexed by code-index-cli
- You have access to .codebase/state.json
- Collection name is generated by code-index-cli (codebase-{uuid})

For default mode (auto hash calculation), use server.py instead.
"""

# MODE Configuration
# "normal" = Use regular Judge with JSON parsing (current behavior)
# "text" = Use TextDirectJudge with structured text (experimental, more reliable)
MODE = "text"
import sys
from typing import Optional, Literal
from fastmcp import FastMCP, Context
from fastmcp.exceptions import ToolError

try:
    from .config import settings
    from .embedder import Embedder
    from .judge import Judge, SearchResult as JudgeSearchResult
    from .text_judge import TextDirectJudge, SearchResult as TextJudgeSearchResult
    from .qdrant_store import QdrantStore, SearchResult
except ImportError:
    from config import settings
    from embedder import Embedder
    from judge import Judge, SearchResult as JudgeSearchResult
    from text_judge import TextDirectJudge, SearchResult as TextJudgeSearchResult
    from qdrant_store import QdrantStore, SearchResult


# Initialize FastMCP server
mcp = FastMCP(
    name="codebase-search-local",
    version="0.1.0"
)

# Initialize services
embedder = Embedder(
    provider=settings.embedder_provider,
    api_key=settings.embedder_api_key,
    model_id=settings.embedder_model_id,
    base_url=settings.embedder_base_url
)

judge = Judge(
    provider=settings.judge_provider,
    api_key=settings.judge_api_key,
    model_id=settings.judge_model_id,
    max_tokens=settings.judge_max_tokens,
    temperature=settings.judge_temperature,
    base_url=settings.judge_base_url,
    system_prompt=settings.judge_system_prompt
)

# Experimental Text Direct Judge for explore_other_workspace
text_judge = TextDirectJudge(
    provider=settings.judge_provider,
    api_key=settings.judge_api_key,
    model_id=settings.judge_model_id,
    max_tokens=settings.judge_max_tokens,
    temperature=settings.judge_temperature,
    base_url=settings.judge_base_url
)

qdrant_store = QdrantStore(
    url=settings.qdrant_url,
    api_key=settings.qdrant_api_key
)


def _format_search_results(query: str, qdrant_collection: str, results: list[SearchResult]) -> str:
    """Format search results as text."""
    if not results:
        return f'No se encontraron coincidencias para "{query}" en la colección "{qdrant_collection}".'

    formatted_parts = [f'Query: {query}', f'Collection: {qdrant_collection}', '']

    for result in results:
        formatted_parts.append(f'Ruta: {result.file_path}')
        formatted_parts.append(f'Score: {result.score:.4f}')
        formatted_parts.append(f'Líneas: {result.start_line}-{result.end_line}')
        formatted_parts.append('---')
        formatted_parts.append(result.code_chunk.strip())
        formatted_parts.append('')

    return '\n'.join(formatted_parts)


def _format_rerank_results(query: str, qdrant_collection: str, reranked: list, summary: Optional[str] = None, usages: Optional[list[str]] = None) -> str:
    """Format reranked results as text."""
    if not reranked:
        return f'No se encontraron resultados relevantes para "{query}" en la colección "{qdrant_collection}".'

    formatted_parts = [f'Query: {query}', f'Collection: {qdrant_collection}', '']

    if summary:
        formatted_parts.append('=== RESUMEN ===')
        formatted_parts.append(summary)
        formatted_parts.append('')
        formatted_parts.append('=== RESULTADOS REORDENADOS ===')
        formatted_parts.append('')

    for result in reranked:
        formatted_parts.append(f'Ruta: {result.file_path}')
        formatted_parts.append(f'Relevancia: {result.relevancia:.4f}')
        formatted_parts.append(f'Score original: {result.score:.4f}')
        formatted_parts.append(f'Líneas: {result.start_line}-{result.end_line}')

        # Extract relevant code snippet (first 2-3 meaningful lines)
        code_lines = result.code_chunk.strip().split('\n')
        snippet_lines = []
        for line in code_lines:
            clean_line = line.strip()
            if clean_line and not clean_line.startswith('//') and not clean_line.startswith('#') and len(clean_line) > 3:
                snippet_lines.append(clean_line)
                if len(snippet_lines) >= 2:  # Limit to 2 meaningful lines
                    break

        snippet = ' | '.join(snippet_lines) if snippet_lines else code_lines[0].strip() if code_lines else 'N/A'
        formatted_parts.append(f'Snippet: {snippet[:150]}{"..." if len(snippet) > 150 else ""}')

        if result.razon:
            formatted_parts.append(f'Razón: {result.razon}')
        formatted_parts.append('---')
        formatted_parts.append(result.code_chunk.strip())
        formatted_parts.append('')

    # Add usages section if present
    if usages and len(usages) > 0:
        formatted_parts.append('=== USAGES DETECTADOS ===')
        for usage in usages:
            formatted_parts.append(f'• {usage}')
        formatted_parts.append('')

    return '\n'.join(formatted_parts)


def _format_search_results_explore(query: str, target_identifier: str, results: list[SearchResult]) -> str:
    """Format search results for explore_other_workspace tool."""
    if not results:
        return f'No se encontraron coincidencias para "{query}" en {target_identifier}.'

    formatted_parts = [f'Query: {query}', f'Target: {target_identifier}', '']

    for result in results:
        formatted_parts.append(f'Ruta: {result.file_path}')
        formatted_parts.append(f'Score: {result.score:.4f}')
        formatted_parts.append(f'Líneas: {result.start_line}-{result.end_line}')
        formatted_parts.append('---')
        formatted_parts.append(result.code_chunk.strip())
        formatted_parts.append('')

    return '\n'.join(formatted_parts)


def _format_rerank_results_explore(query: str, target_identifier: str, reranked: list, summary: Optional[str] = None, usages: Optional[list[str]] = None) -> str:
    """Format reranked results for explore_other_workspace tool."""
    if not reranked:
        return f'No se encontraron resultados relevantes para "{query}" en {target_identifier}.'

    formatted_parts = [f'Query: {query}', f'Target: {target_identifier}', '']

    if summary:
        formatted_parts.append('=== RESUMEN ===')
        formatted_parts.append(summary)
        formatted_parts.append('')
        formatted_parts.append('=== RESULTADOS REORDENADOS ===')
        formatted_parts.append('')

    for result in reranked:
        formatted_parts.append(f'Ruta: {result.file_path}')
        formatted_parts.append(f'Relevancia: {result.relevancia:.4f}')
        formatted_parts.append(f'Score original: {result.score:.4f}')
        formatted_parts.append(f'Líneas: {result.start_line}-{result.end_line}')

        # Extract relevant code snippet (first 2-3 meaningful lines)
        code_lines = result.code_chunk.strip().split('\n')
        snippet_lines = []
        for line in code_lines:
            clean_line = line.strip()
            if clean_line and not clean_line.startswith('//') and not clean_line.startswith('#') and len(clean_line) > 3:
                snippet_lines.append(clean_line)
                if len(snippet_lines) >= 2:  # Limit to 2 meaningful lines
                    break

        snippet = ' | '.join(snippet_lines) if snippet_lines else code_lines[0].strip() if code_lines else 'N/A'
        formatted_parts.append(f'Snippet: {snippet[:150]}{"..." if len(snippet) > 150 else ""}')

        if result.razon:
            formatted_parts.append(f'Razón: {result.razon}')
        formatted_parts.append('---')
        formatted_parts.append(result.code_chunk.strip())
        formatted_parts.append('')

    # Add usages section if present
    if usages and len(usages) > 0:
        formatted_parts.append('=== USAGES DETECTADOS ===')
        for usage in usages:
            formatted_parts.append(f'• {usage}')
        formatted_parts.append('')

    return '\n'.join(formatted_parts)


@mcp.tool
async def explore_other_workspace(
    query: str,
    qdrant_collection: Optional[str] = None,
    workspace_path: Optional[str] = None,
    path: Optional[str] = None,
    mode: Literal["rerank", "summary"] = "rerank",
    include_docs: bool = False,
    include_config: bool = False,
    search_intent: Optional[str] = None,
    ctx: Context = None
) -> str:
    """Explora y busca en colecciones de otros workspaces diferentes al actual.

    Esta herramienta permite realizar búsquedas semánticas en workspaces remotos o diferentes
    al actual, útil para buscar patrones en proyectos relacionados o diferentes codebases.

    Usa JSON Schema Structured Outputs para garantizar respuestas completas y estructuradas.
    Filtra archivos de documentación por defecto para enfocarse en código.

    Args:
        query: Texto natural a buscar en el código
        qdrant_collection: Nombre de colección Qdrant explícito (prioridad alta)
        workspace_path: Ruta del workspace alternativo (usado si no hay qdrant_collection)
        path: Prefijo de ruta opcional para filtrar resultados
        mode: Modo de operación - "rerank" solo reordena, "summary" incluye resumen
        include_docs: Si True, incluye archivos de documentación (.md, .txt, etc.). Por defecto False.
        include_config: Si True, incluye archivos de configuración (.json, .ini, .yaml, etc.). Por defecto False.
        search_intent: Palabra clave para concatenar a la query (ej: "implementation", "usage", "flow"). Se concatena como palabra adicional.
        ctx: FastMCP context for logging

    Returns:
        Resumen estructurado en markdown con: Top Files, Code Fragments, Usages, Inference
    """
    try:
        # Log request
        if ctx:
            await ctx.info(f"[Explore Other LOCAL] Query: {query}, Collection: {qdrant_collection}, Workspace: {workspace_path}, Mode: {mode}")
        else:
            print(f"[Explore Other LOCAL] Query: {query}, Collection: {qdrant_collection}, Workspace: {workspace_path}, Mode: {mode}", file=sys.stderr)

        # Validate inputs
        if not query or not query.strip():
            raise ToolError("El parámetro 'query' es requerido y no puede estar vacío.")

        # Determine collection to use
        final_collection_name = None
        target_identifier = None

        if qdrant_collection and qdrant_collection.strip():
            # Priority 1: Use explicit collection name
            final_collection_name = qdrant_collection.strip()
            target_identifier = f"colección '{final_collection_name}'"
        elif workspace_path and workspace_path.strip():
            # Priority 2: Calculate from workspace path
            normalized_workspace = qdrant_store._normalize_workspace_path(workspace_path.strip())
            final_collection_name = qdrant_store._get_collection_name(normalized_workspace)
            target_identifier = f"workspace '{workspace_path}' (colección: {final_collection_name})"
        else:
            raise ToolError(
                "Debes proporcionar 'qdrant_collection' O 'workspace_path'.\n\n"
                "- qdrant_collection: Nombre explícito de la colección (ej: 'codebase-f93e99958acc444e')\n"
                "- workspace_path: Ruta del workspace (se calculará la colección automáticamente)\n\n"
                "Si ambos están presentes, se usa qdrant_collection (prioridad alta)."
            )

        # Concatenate search_intent to query if provided
        final_query = query
        if search_intent and search_intent.strip():
            final_query = f"{query} {search_intent.strip()}"
            print(f"[DEBUG Explore Other LOCAL] Query modificada con search_intent: '{final_query}'", file=sys.stderr)

        # Step 1: Perform initial search
        if ctx:
            await ctx.info(f"[Explore Other LOCAL] Buscando en {target_identifier} para query: '{final_query}'")

        vector = await embedder.create_embedding(final_query)
        search_results = await qdrant_store.search(
            vector=vector,
            workspace_path="",  # Not used when collection_name is provided
            directory_prefix=path,
            min_score=settings.search_min_score,
            max_results=settings.search_max_results,
            collection_name=final_collection_name
        )

        if not search_results:
            return f'No se encontraron resultados para "{final_query}" en {target_identifier}.'

        # Step 2: Filter documentation files if include_docs=False
        if not include_docs:
            original_count = len(search_results)
            search_results = [
                r for r in search_results
                if not r.file_path.endswith(('.md', '.txt', '.rst', '.adoc', '.markdown'))
            ]
            filtered_count = original_count - len(search_results)
            if filtered_count > 0:
                print(f"[DEBUG] Filtrados {filtered_count} archivos de documentación", file=sys.stderr)
                if ctx:
                    await ctx.info(f"[Explore Other LOCAL] Filtrados {filtered_count} archivos de documentación")

        # Step 3: Filter configuration files if include_config=False
        if not include_config:
            original_count = len(search_results)
            search_results = [
                r for r in search_results
                if not r.file_path.endswith(('.json', '.ini', '.yaml', '.yml', '.toml', '.xml', '.env', '.config'))
            ]
            filtered_count = original_count - len(search_results)
            if filtered_count > 0:
                print(f"[DEBUG] Filtrados {filtered_count} archivos de configuración", file=sys.stderr)
                if ctx:
                    await ctx.info(f"[Explore Other LOCAL] Filtrados {filtered_count} archivos de configuración")

        if not search_results:
            return f'No se encontraron resultados de código para "{final_query}". Usa include_docs=True o include_config=True para incluir archivos de documentación/configuración.'

        # Step 3: Convert to TextDirectJudge format
        text_judge_results = [
            TextJudgeSearchResult(
                file_path=r.file_path,
                code_chunk=r.code_chunk,
                start_line=r.start_line,
                end_line=r.end_line,
                score=r.score
            )
            for r in search_results
        ]

        # Step 4: Rerank with JSON Schema structured outputs
        print(f"[DEBUG] Rerankando con JSON Schema estructurado...", file=sys.stderr)

        if ctx:
            await ctx.info(f"[Explore Other LOCAL] Rerankando {len(text_judge_results)} resultados con JSON Schema")

        # Rerank with structured outputs
        summary = await text_judge.rerank_structured(query, text_judge_results)

        print(f"[DEBUG] Resumen estructurado generado: {len(summary.top_files)} archivos, {len(summary.code_fragments)} fragmentos", file=sys.stderr)

        # Format as markdown (same as superior_codebase_rerank)
        markdown = f"""# Resultados de búsqueda: {summary.query}

**Total de archivos:** {summary.total_files}
**Total de fragmentos:** {summary.total_fragments}

## Top {len(summary.top_files)} Archivos (calificación IA)

"""
        for i, file in enumerate(summary.top_files, 1):
            markdown += f"""### {i}. `{file.file_path}`
**Relevancia:** {file.relevance}
**Razón:** {file.reason}
**Líneas relevantes:** {file.relevant_lines}

"""

        if summary.code_fragments:
            markdown += f"\n## Fragmentos de Código ({len(summary.code_fragments)} fragmentos)\n\n"
            for i, frag in enumerate(summary.code_fragments, 1):
                # Detect language from file extension
                ext = frag.file_path.split('.')[-1] if '.' in frag.file_path else ''
                lang_map = {
                    'ts': 'typescript', 'js': 'javascript', 'py': 'python',
                    'java': 'java', 'cpp': 'cpp', 'c': 'c', 'go': 'go',
                    'rs': 'rust', 'rb': 'ruby', 'php': 'php', 'cs': 'csharp'
                }
                lang = lang_map.get(ext, '')

                markdown += f"""### {i}. `{frag.file_path}` (líneas {frag.start_line}-{frag.end_line})

**Explicación:** {frag.explanation}

```{lang}
{frag.code_snippet}
```

"""

        if summary.usages:
            markdown += f"\n## Usages ({len(summary.usages)} invocaciones)\n\n"
            for usage in summary.usages:
                markdown += f"- **{usage.function_name}** llamada en `{usage.file_path}:{usage.line_number}`  \n  {usage.context}\n\n"

        markdown += f"\n## Inferencia\n\n{summary.inference}\n"

        # Return formatted markdown
        return markdown

    except ToolError:
        raise
    except Exception as e:
        error_msg = str(e)
        if ctx:
            await ctx.info(f"[Explore Other LOCAL] Error: {error_msg}")
        else:
            print(f"[Explore Other LOCAL] Error: {error_msg}", file=sys.stderr)

        # Re-raise the exception instead of trying to use potentially undefined variables
        raise


@mcp.tool
async def superior_codebase_rerank(
    query: str,
    qdrant_collection: str,
    path: Optional[str] = None,
    mode: Literal["rerank", "summary"] = "rerank",
    include_docs: bool = False,
    include_config: bool = False,
    search_intent: Optional[str] = None,
    ctx: Context = None
) -> str:
    """Realiza una búsqueda semántica y reordena los resultados usando un LLM Judge.

    Esta herramienta está diseñada para trabajar con workspaces indexados por code-index-cli.
    Requiere el nombre de colección explícito desde .codebase/state.json.

    Args:
        query: Texto natural a buscar en el código
        qdrant_collection: Nombre de colección Qdrant (REQUERIDO - desde .codebase/state.json)
        path: Prefijo de ruta opcional para filtrar resultados
        mode: Modo de operación - "rerank" solo reordena, "summary" incluye resumen
        include_docs: Si True, incluye archivos de documentación (.md, .txt, etc.). Por defecto False.
        include_config: Si True, incluye archivos de configuración (.json, .ini, .yaml, etc.). Por defecto False.
        search_intent: Palabra clave para concatenar a la query (ej: "implementation", "usage", "flow"). Se concatena como palabra adicional.
        ctx: FastMCP context for logging

    Returns:
        Resultados reordenados formateados como texto, opcionalmente con resumen
    """
    try:
        # Log request
        if ctx:
            await ctx.info(f"[Rerank LOCAL] Query: {query}, Collection: {qdrant_collection}, Mode: {mode}")
        else:
            print(f"[Rerank LOCAL] Query: {query}, Collection: {qdrant_collection}, Mode: {mode}", file=sys.stderr)

        # Validate inputs
        if not query or not query.strip():
            raise ToolError("El parámetro 'query' es requerido y no puede estar vacío.")

        if not qdrant_collection or not qdrant_collection.strip():
            raise ToolError(
                "El parámetro 'qdrantCollection' es requerido.\n\n"
                "Este servidor está configurado para modo LOCAL (code-index-cli).\n"
                "Debes leer el archivo .codebase/state.json del workspace y pasar el campo 'qdrantCollection'.\n\n"
                'Ejemplo: { "query": "login function", "qdrantCollection": "codebase-f93e99958acc444e" }'
            )

        # Concatenate search_intent to query if provided
        final_query = query
        if search_intent and search_intent.strip():
            final_query = f"{query} {search_intent.strip()}"
            print(f"[DEBUG Rerank LOCAL] Query modificada con search_intent: '{final_query}'", file=sys.stderr)

        # Step 1: Perform initial search
        print(f"\n[DEBUG Rerank LOCAL] Buscando resultados para query: '{final_query}'", file=sys.stderr)
        print(f"[DEBUG Rerank LOCAL] Colección: {qdrant_collection}", file=sys.stderr)
        print(f"[DEBUG Rerank LOCAL] Min score: {settings.search_min_score}", file=sys.stderr)
        print(f"[DEBUG Rerank LOCAL] Max results: {settings.search_max_results}", file=sys.stderr)

        if ctx:
            await ctx.info(f"[Rerank LOCAL] Buscando resultados para query: '{final_query}'")
            await ctx.info(f"[Rerank LOCAL] Colección: {qdrant_collection}")
            await ctx.info(f"[Rerank LOCAL] Min score: {settings.search_min_score}")
            await ctx.info(f"[Rerank LOCAL] Max results: {settings.search_max_results}")

        vector = await embedder.create_embedding(final_query)

        print(f"[DEBUG Rerank LOCAL] Vector generado: dimensión={len(vector)}, primeros 5 valores={vector[:5]}", file=sys.stderr)

        if ctx:
            await ctx.info(f"[Rerank LOCAL] Vector generado: dimensión={len(vector)}, primeros 5 valores={vector[:5]}")

        search_results = await qdrant_store.search(
            vector=vector,
            workspace_path="",  # Not used when collection_name is provided
            directory_prefix=path,
            min_score=settings.search_min_score,
            max_results=settings.search_max_results,
            collection_name=qdrant_collection
        )

        print(f"[DEBUG Rerank LOCAL] Resultados de Qdrant: {len(search_results)} encontrados", file=sys.stderr)
        if search_results:
            print(f"[DEBUG Rerank LOCAL] Mejor score: {max(r.score for r in search_results):.6f}", file=sys.stderr)
            print(f"[DEBUG Rerank LOCAL] Peor score: {min(r.score for r in search_results):.6f}", file=sys.stderr)

        if ctx:
            await ctx.info(f"[Rerank LOCAL] Resultados de Qdrant: {len(search_results)} encontrados")
            if search_results:
                await ctx.info(f"[Rerank LOCAL] Mejor score: {max(r.score for r in search_results):.6f}")
                await ctx.info(f"[Rerank LOCAL] Peor score: {min(r.score for r in search_results):.6f}")

        if not search_results:
            return f'No se encontraron resultados para "{final_query}" en la colección "{qdrant_collection}".'

        # Step 2: Filter documentation files if include_docs=False
        if not include_docs:
            original_count = len(search_results)
            search_results = [
                r for r in search_results
                if not r.file_path.endswith(('.md', '.txt', '.rst', '.adoc', '.markdown'))
            ]
            filtered_count = original_count - len(search_results)
            if filtered_count > 0:
                print(f"[DEBUG] Filtrados {filtered_count} archivos de documentación", file=sys.stderr)
                if ctx:
                    await ctx.info(f"[Rerank LOCAL] Filtrados {filtered_count} archivos de documentación")

        # Step 3: Filter configuration files if include_config=False
        if not include_config:
            original_count = len(search_results)
            search_results = [
                r for r in search_results
                if not r.file_path.endswith(('.json', '.ini', '.yaml', '.yml', '.toml', '.xml', '.env', '.config'))
            ]
            filtered_count = original_count - len(search_results)
            if filtered_count > 0:
                print(f"[DEBUG] Filtrados {filtered_count} archivos de configuración", file=sys.stderr)
                if ctx:
                    await ctx.info(f"[Rerank LOCAL] Filtrados {filtered_count} archivos de configuración")

        if not search_results:
            return f'No se encontraron resultados de código para "{query}". Usa include_docs=True o include_config=True para incluir archivos de documentación/configuración.'

        # Step 3: Rerank with JSON Schema structured outputs
        print(f"[DEBUG] Rerankando con JSON Schema estructurado...", file=sys.stderr)

        if ctx:
            await ctx.info(f"[Rerank LOCAL] Rerankando {len(search_results)} resultados con JSON Schema")

        # Convert to TextJudge format
        text_judge_results = [
            TextJudgeSearchResult(
                file_path=r.file_path,
                code_chunk=r.code_chunk,
                start_line=r.start_line,
                end_line=r.end_line,
                score=r.score
            )
            for r in search_results
        ]

        # Rerank with structured outputs
        summary = await text_judge.rerank_structured(query, text_judge_results)

        print(f"[DEBUG] Resumen estructurado generado: {len(summary.top_files)} archivos, {len(summary.code_fragments)} fragmentos", file=sys.stderr)

        # Format as markdown
        markdown = f"""# Resultados de búsqueda: {summary.query}

**Total de archivos:** {summary.total_files}
**Total de fragmentos:** {summary.total_fragments}

## Top {len(summary.top_files)} Archivos (calificación IA)

"""
        for i, file in enumerate(summary.top_files, 1):
            markdown += f"""### {i}. `{file.file_path}`
**Relevancia:** {file.relevance}
**Razón:** {file.reason}
**Líneas relevantes:** {file.relevant_lines}

"""

        if summary.code_fragments:
            markdown += f"\n## Fragmentos de Código ({len(summary.code_fragments)} fragmentos)\n\n"
            for i, frag in enumerate(summary.code_fragments, 1):
                # Detect language from file extension
                ext = frag.file_path.split('.')[-1] if '.' in frag.file_path else ''
                lang_map = {
                    'ts': 'typescript', 'js': 'javascript', 'py': 'python',
                    'java': 'java', 'cpp': 'cpp', 'c': 'c', 'go': 'go',
                    'rs': 'rust', 'rb': 'ruby', 'php': 'php', 'cs': 'csharp'
                }
                lang = lang_map.get(ext, '')

                markdown += f"""### {i}. `{frag.file_path}` (líneas {frag.start_line}-{frag.end_line})

**Explicación:** {frag.explanation}

```{lang}
{frag.code_snippet}
```

"""

        if summary.usages:
            markdown += f"\n## Usages ({len(summary.usages)} invocaciones)\n\n"
            for usage in summary.usages:
                markdown += f"- **{usage.function_name}** llamada en `{usage.file_path}:{usage.line_number}`  \n  {usage.context}\n\n"

        markdown += f"\n## Inferencia\n\n{summary.inference}\n"

        # Return formatted markdown
        return markdown

    except ToolError:
        raise
    except Exception as e:
        error_msg = str(e)
        if ctx:
            await ctx.info(f"[Rerank LOCAL] Error: {error_msg}")
        else:
            print(f"[Rerank LOCAL] Error: {error_msg}", file=sys.stderr)

        # Re-raise the exception instead of trying to use potentially undefined variables
        raise


# Entry point for fastmcp CLI
if __name__ == "__main__":
    print("[MCP] Servidor `codebase-search-local` inicializado y listo.", file=sys.stderr)
    mcp.run()
